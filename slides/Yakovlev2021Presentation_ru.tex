\documentclass{beamer}
\beamertemplatenavigationsymbolsempty
\usecolortheme{beaver}
\setbeamertemplate{blocks}[rounded=true, shadow=true]
\setbeamertemplate{footline}[page number]
%
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amssymb,amsfonts,amsmath,mathtext}
\usepackage{subfig}
\usepackage[all]{xy} % xy package for diagrams
\usepackage{array}
\usepackage{multicol}% many columns in slide
\usepackage{hyperref}% urls
\usepackage{hhline}%tables
% Your figures are here:
\graphicspath{ {fig/} {../fig/} }

\usepackage{algorithm, algorithmic}
\usepackage{multirow}

%----------------------------------------------------------------------------------------------------------
\title[\hbox to 56mm{Алгоритм поиска архитектуры}]{Дифференцируемый алгоритм поиска архитектуры модели с контролем её сложности}
\author[К.\,Д. Яковлев]{Константин Дмитриевич Яковлев}
\institute{Московский физико-технический институт}
\date{\footnotesize
\par\smallskip\emph{Курс:} Автоматизация научных исследований\par (практика, В.\,В.~Стрижов)/Группа 874
\par\smallskip\emph{Эксперт:} В.\,В.~Стрижов
\par\smallskip\emph{Консультант:} О.\,С.~Гребенькова, ~ О.\,Ю.~Бахтеев
\par\bigskip\small 2021}
%----------------------------------------------------------------------------------------------------------
\begin{document}
%----------------------------------------------------------------------------------------------------------
\begin{frame}
\thispagestyle{empty}
\maketitle
\end{frame}
%-----------------------------------------------------------------------------------------------------
\begin{frame}{Цель исследования}
\begin{block}{Цель} 
Предложить метод поиска архитектуры модели глубокого обучения с контролем сложности модели.
\end{block}

~\\
\begin{block}{Проблема}
Семейство моделей глубокого обучения имеет избытычное число параметров. Использование моделей, работающих с дискретной архитектурой, является вычислительно сложной задачей.
\end{block}
~\\
\begin{block}{Метод решения}

В основе метода лежит дифференцируемый алгоритм поиска архитектуры (DARTS). Гиперсеть выступает в качестве функции релаксации. Гиперсеть -- это модель, генерирующая параметры другой модели. 
\end{block}

\end{frame}
%-----------------------------------------------------------------------------------------------------
\begin{frame}{DARTS и линейная гиперсеть}

%\begin{columns}[c]
%\column{0.5\textwidth}
%\begin{figure}
%	\includegraphics[width=1\textwidth]{reduction}
%	\caption{Пример архитектуры}
%\end{figure}
%\column{0.5\textwidth}

\begin{figure}
	\includegraphics[width=1\textwidth]{reduction}
\end{figure}


\begin{itemize}
\item Значения в узлах: $$x^{(j)} = \sum_{i < j}o^{(i, j)}(x^{(i)})$$

\item Смешанная операция: $$\hat{o}^{(i, j)}(x) = \sum_{o\in\mathcal{O}}\alpha^{(i, j)}_oo(x)$$

\item Линейная гиперсеть: $$\mathbf{\alpha} = \lambda\mathbf{b}_1 + \mathbf{b}_2$$

\end{itemize}


%\end{columns}
\end{frame}


%----------------------------------------------------------------------------------------------------------
\begin{frame}{Основная литература}

\begin{thebibliography}{1}


\bibitem{darts} 
Hanxiao Liu and Karen Simonyan and Yiming Yang. 
\textit{DARTS: Differentiable Architecture Search}.
CoRR, 2018.

\bibitem{hypernet} 
David Ha and Andrew M. Dai and Quoc V. Le.
\textit{HyperNetworks}. 
CoRR, 2016.

\bibitem{FairDarts}
Xiangxiang Chu, Tianbao Zhou, Bo Zhang, and Jixiang Li.
\textit{Fair DARTS: Eliminating Unfair Advantages in
	Differentiable Architecture Search}.
CoRR, 2019.

\end{thebibliography}			
\end{frame}




%----------------------------------------------------------------------------------------------------------
\begin{frame}{Постановка задачи поиска архитектуры модели}

\begin{center}
\includegraphics[scale=0.3]{reduction.eps}
\end{center}

\begin{itemize}

\item \textbf{Узлы}:

 $\{x^{(i)}\}_{i=1}^N$ -- узлы ориентированного ациклического графа. 

\item \textbf{Значение в текущем узле}:

 $$x^{(j)} = \sum_{i < j}o^{(i, j)}(x^{(i)})~~o^{(i, j)} \in\mathcal{O}$$


\item \textbf{Смешанная операция}: $$\hat{o}^{(i, j)}(x) = \sum_{o\in \mathcal{O}} \alpha_o^{(i, j)}o(x)$$

\item \textbf{Вектор параметров архитектуры}: $$\alpha = [\alpha^{(i, j)}]$$

\end{itemize}
\end{frame}



\begin{frame}{Линейная гиперсеть задает параметры архитектуры}

\begin{block}{Гиперсеть}
$$\mathbf{G} : \Lambda \times \mathbb{U} \rightarrow \mathbb{A}.$$
$\mathbb{A}$ -- пространство параметров архитектуры, $\mathbb{U}$ -- множество параметров гиперсети.
\end{block}

\begin{itemize}
\item \textbf{Вектор параметров архитектуры определяется гиперсетью}:
$$\alpha = \lambda\mathbf{b}_1 + \mathbf{b}_2.$$

\item \textbf{Задача оптимизации}:
$$\min_{\alpha}\mathcal{L}_\text{val}(\mathbf{w}^*(\alpha), \alpha),$$ $$
 \mathrm{s.t.}\quad \mathbf{w}^* = \arg\min_{\mathbf{w}}\mathcal{L}_\text{train}(\mathbf{w}, \alpha).$$
\end{itemize}



\end{frame}
%%----------------------------------------------------------------------------------------------------------
\begin{frame}{DARTS}
\begin{itemize}
\item \textbf{Алгоритм  DARTS}:
 \begin{algorithm}[H]
\begin{algorithmic}[1]
\caption{DARTS -- Differentiable Architecture Search}
\STATE Для каждого узла создадим смешанную операцию $\hat{o}^{(i, j)}$, параметризованную $\alpha^{(i, j)}$
\WHILE{алгоритм не сошелся} 
\STATE  обновить $\alpha$: $\nabla_\alpha \mathcal{L}_\text{val}\bigl(\mathbf{w} - \xi\nabla_{\mathbf{w}}\mathcal{L}_\text{train}(\mathbf{w}, \alpha), \alpha\bigr)$
\STATE обновить веса $\mathbf{w}$: $\nabla_\mathbf{w}\mathcal{L}_\text{train}(\mathbf{w}, \alpha)$
\ENDWHILE
\STATE получить окончательную архитектуру из полученного $\alpha$
\end{algorithmic}
\end{algorithm}
\item \textbf{Получение дискретной архитектуры}:

$$o^{(i, j)} =\arg\max_{o\in\mathcal{O}}\alpha_o^{(i, j)}.$$

\end{itemize}

\end{frame}
%%----------------------------------------------------------------------------------------------------------
\begin{frame}{Вычислительный эксперимент}

\begin{block}{Цель}
Получение зависимости качества работы предложенного метода от параметра гиперсети $\lambda \in \{10^{-4}, 10^{-3}, 10^{-2}, 10^{-1}\}$. Эксперимент проводится на выборке MNIST.
\end{block}

\begin{block}{Критерии качества}
 $$\mathrm{Precision} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP}}.$$
 В качестве $\mathcal{L}_\text{train}(\mathbf{w}, \alpha), ~\mathcal{L}_\text{val}(\mathbf{w}, \alpha)$ рассматривается кросс-энтропия.
\end{block}

\end{frame}

\begin{frame}{Качество Hypernet}

\begin{center}
Зависимость качества модели от числа прошедших эпох для разных параметров $\lambda$ гиперсети.
\includegraphics[width=0.6\textwidth]{main_100_exp}
\end{center}

Для $\lambda = 10^{-1}$ качество модели заметно хуже, чем для других значениях $\lambda$. Также для каждой эпохи и для каждого $\lambda \in \{10^{-4}, 10^{-3}, 10^{-2}\}$ качество модели практически не меняется.

\end{frame}


\begin{frame}{Сравнение Hypernet и DARTS}
\begin{center}
Значения качества моделей на валидации.
\begin{table}[H]
	\begin{tabular}{ |c|c|c|c|c| }
	\hline
	 \multirow{2}{*}{Модель} & \multicolumn{4}{c|}{Precision, \%} \\ \cline{2-5}
	 		& эпоха 30 & эпоха 50 & эпоха 70 & эпоха 100\\
	 \hline
 	Hypernet, $\lambda = 10^{-1}$ &96,3500 & 95,4800 & 94,1200 & 90,6333  \\ 
 	Hypernet, $\lambda = 10^{-2}$ &95,8900 & 96,7167& 91,0633 & 95,3133 \\ 
 	Hypernet, $\lambda = 10^{-3}$ &95,9133 & 96,6200 & 90,6400 & 95,6400 \\ 
 	Hypernet, $\lambda = 10^{-4}$ &95,9733 & 96,5367 & 90,4067 & 95,7533\\
 	\hline
 	DARTS, $\lambda = 10^{-1}$ &86,6000 &87,3967 & 89,3433 & 89,5067 \\
 	DARTS, $\lambda = 10^{-2}$ & 84,1333 & 90,6333 &91,9100 & 92,7333\\
 	DARTS, $\lambda = 10^{-3}$ &97.6533 & 97.5800 & 98.0833 & 97,9467 \\
 	DARTS, $\lambda = 10^{-4}$ & \textbf{98,5800} &  \textbf{98,8867}&\textbf{98,9467}&\textbf{99,2400} \\
 	\hline
\end{tabular}
\end{table}
\end{center}

Для модели Hypernet качество на валидации уменьшается с ростом номера эпохи.

\end{frame}
%%----------------------------------------------------------------------------------------------------------
\begin{frame}{Заключение}
    \begin{block}{Результаты}
    \begin{itemize}
        \item Предложен метод, позволяющий контролировать сложность модели в процессе поиска архитектуры.
        \item Метод обладает тем свойством, что изменение сложности итоговой модели происходит заменой параметра $\lambda$ гиперсети без дополнительного обучения.
        \item Также результаты показывают, что данный метод сопоставим по качеству на валидационной выборке с DARTS.
    \end{itemize}
    \end{block}
\end{frame}
%%----------------------------------------------------------------------------------------------------------
%\end{document} 
%\end{frame}
%%-----------------------------------------------------------------------------------------------------
%
%
%\end{frame}
%%----------------------------------------------------------------------------------------------------------
%\begin{frame}{���������� ������}
%\end{frame}
%%----------------------------------------------------------------------------------------------------------
%\begin{frame}{�������}
%\end{frame}
%%----------------------------------------------------------------------------------------------------------
%\begin{frame}{�������������� �����������}
%\end{frame}
%%----------------------------------------------------------------------------------------------------------
%\begin{frame}{����������}
%\end{frame}
%----------------------------------------------------------------------------------------------------------
\end{document} 